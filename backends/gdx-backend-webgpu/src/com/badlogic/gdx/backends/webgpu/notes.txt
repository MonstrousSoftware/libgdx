Notes on webgpu backend.

4/5/2025:
Synced libgdx repo on 4/5/2005 (latest update from 27/04/2025). Version 1.13.2.
Uses Gradle 8.12.

Error message: This project uses AGP 8.7.3, latest supported AGP is 7.4.0.
It means the IDE doesn't support the required version of the Android Gradle Plugin.
This is fixed by updating Intellij IDEA to update 2025.1 (built April 15, 2025).

Started creating gdx-backend-webgpu by copying gdx-backend-lwjgl3 and renaming
everything Lwjgl3 to WebGPU.

For now, copied all the backend files even when it is not graphics API related,
e.g. audio. Accept or deal with the code duplication later.

How to deal with multiple platforms? We are now tied to the LWJGL3 one.

5/5/2025:
Created tests/gdx-tests-webgpu based on gdx-tests-lwjgl3.

Added the generated jnr files from webgpu-to-java (https://github.com/MonstrousSoftware/java-to-webgpu)
to the libgdx backend (backends.webgpu.webgpu) (maybe the folder name could be better).
Needed to adapt the jnr generator to create the correct package name and import statements.

Resource folder added under gdx-backend-webgpu for the DLL files. (todo subdir per platform).
Shader source was added as a String to the HelloTriangle code to avoid too many loose files.

HelloTriangle test now works (calling GLFW and native WebGPU directly).

WebGPUTest uses WebGPUApplication and some native WebGPU calls to render a triangle.
The listener needs to create its own render pass (this will later be done by SpriteBatch or ModelBatch),
while WebGPUWindow.update() obtains the next render surface and presents the target view.
Update: the command encoder is created and finished in Window, and can be obtained via app.getCommandEncoder(),
render pass is created in Listener (because you may want multiple render passes).

LibGDX supports multiple windows per application.  This does not work yet for WebGPU (crash).

For audio, the webgpu backend simply refers to the lwjgl3 backend, so we don't duplicate non-graphics code.
This means we can remove the audio subfolder from gdx-backend-webgpu.



6/5/2024:
Crash of Application.newWindow() was because of the sharedContext parameter which seems related to GL context.  Crash fixed by passing a 0 instead.
To think which resources should be maintained at window level rather than application level, e.g. surface, device?, queue?
Moved surface, device, queue, targetView and commandEncoder to Window.  Application exposes these resource to user code by passing the resources from the current window.
WebGPU initialisation is mostly done at Window level now.

WebGPUTest now can create multiple windows. Use a mouse click in the window to create a child window.
Application exits when last window is closed.

Note: had to rename the .github/workflows folder (as a way to disable the workflows) to avoid push conflicts with automatic formatting workflows
and getting regular emails about missing permissions.

Next steps:
- include WebGPU abstraction classes
- SpriteBatch / Mesh

Created a wrapper folder which contain Java convenience classes of several WebGPU concepts (device, adapter, command encoder, buffer, etc.)
The webgpu code in Window was adapted to use these classes.
To get the raw pointer to use e.g. in a webgpu function call, use the getHandle() method.

Instead of replicating the internals of libgdx SpriteBatch (e.g. using a Mesh) we use a version that is functionally equivalent.

WGPUTexture still needs to be aligned to Texture.

RenderPassBuilder and PipelineSpecification need cleaning up or replacing.

VertexAttributes is reinvented. To be aligned.

Added depth texture to Window. Applcation exports textureview and textureformat (needed to build render pass).

07/05:
Many classes need access to the webGPU instance and the app instance (because this gives access to device, queue, etc.)
(app instance actually relies on current Window).  So many classes include the following type of code:

        public class WebGPUBindGroup implements Disposable {
            private final WebGPUApplication app;
            private final WebGPU_JNI webGPU;


            public WebGPUBindGroup(WebGPUBindGroupLayout layout) {
                app = (WebGPUApplication) Gdx.app;
                webGPU = app.getWebGPU();
                ...
            }
        }

This is the equivalent of libgdx code using Gdx.gl and Gdx.app but unfortunately more wordy (since we don't want to modify Gdx itself).

Perhaps we should put the WebGPU context in Graphics rather than Window, then we can use:
    WebGPUGraphics gfx = (WebGPUGraphics)Gdx.graphics;
    WebGPU_JNI webGPU = gfx.getWebGPU();
    gfx.getDevice()
    gfx.getQueue() etc.

Still just as wordy, but more logical.


Perhaps PipelineLayout should be integrated into PipelineSpec.  These are 2 objects required to create or find a pipeline.

libgdx VertexAttributes uses a String as alias to bind with shader code.  In webgpu we use an integer to bind.
WebGPU has a vertex format enum that gives type and number of components, e.g. Uint8x4 whereas libgdx uses type (e.g. GL_FLOAT) + numComponents

Got WebGPUSpriteBatch to work to display a texture.  SpriteBatch and Texture are internally very different from the libgdx equivalent.

Should WebGPUSpriteBatch extend SpriteBatch? This way we don't have to copy all the draw methods, setColor, etc.

Also if WebGPUTexture extends Texture we can supply WebGPUTexture as draw parameter (but it would also accept a regular Texture
which is an error).

In the Vulkan version by Stephan Lebed, a regular Texture is accepted but cast to VulkanTexture, which seems dangerous...
His VulkanTexture extends Texture.
Note that his VulkanSpriteBatch implements Batch (i.e. implements all methods).

        @Override
        public void draw(Texture texture, float[] spriteVertices, int offset, int count) {
            if (!drawing) throw new IllegalStateException("Batch.begin must be called before draw.");


            VulkanTexture vkTexture = (VulkanTexture) texture;


WebGPUTexture was brought more in line with Texture and now extends Texture.  Uses Pixmap and TextureData.
The Texture.data member had to be duplicated because it is package private and cannot be accessed by the subclass.
To check if managed textures work and if pixmaps are disposed properly.

Added a label parameter to some of the different Texture constructurs, e.g. the source file name to aid with debugging.

WebGPUSpriteBatch
-----------------
- The blend methods use values of type WGPUBlendFactor (e.g. WGPUBlendFactor.SrcAlpha) instead of int (e.g. GL_SRC_ALPHA). To differentiate
the methods are called xxxxFactor instead of xxxxFunc.  The original methods are also provide and perform a translation to/from GL constants to ensure
the WebGPUSpriteBatch is compatible with Batch.
- setShader() variant with WebGPUShaderProgram instead of ShaderProgram.
- getShader() always returns null.
- The blendOpColor and blendOpAlpha are not modified by spritebatch methods and is set to Add.
- begin() has an extra Color parameter to set the background colour.
- whereas the libgdx SpriteBatch can handle more sprites than fit in the vertex buffer by flushing and restarting, this does not work
for WebGPU as the buffer cannot be reused after each draw call but needs to be maintained until the end of the frame.
If there are too many sprites an exception is thrown. In such a case, use a larger number in the sprite batch constructor.

TextureRegion
-------------
This works out of the box as long as you provide a WebGPUTexture as input. (You cannot create a Texture anyway without a GL context).

Sprite
------
Works out of the box as long as you provide a WebGPUTexture as input.

BitmapFont
-----------
Had to be copied to WebGPUBitmapFont because it calls new Texture which should be new WebGPUTexture. (line 134)
Glyph subclass is used from the original.
This also means BitmapFontCache and GlyphLayout need to be copied because of type changes from BitmapFont to WebGPUBitmapFont.
Unfortunately , that's a lot of duplicated lines for a few trivial changes.


