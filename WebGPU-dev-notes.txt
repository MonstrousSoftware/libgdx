Notes on webgpu backend.

4/5/2025:
Synced libgdx repo on 4/5/2005 (latest update from 27/04/2025). Version 1.13.2.
Uses Gradle 8.12.

Error message: This project uses AGP 8.7.3, latest supported AGP is 7.4.0.
It means the IDE doesn't support the required version of the Android Gradle Plugin.
This is fixed by updating Intellij IDEA to update 2025.1 (built April 15, 2025).

Started creating gdx-backend-webgpu by copying gdx-backend-lwjgl3 and renaming
everything Lwjgl3 to WebGPU.

For now, copied all the backend files even when it is not graphics API related,
e.g. audio. Accept or deal with the code duplication later.

How to deal with multiple platforms? We are now tied to the LWJGL3 one.

5/5/2025:
Created tests/gdx-tests-webgpu based on gdx-tests-lwjgl3.

Added the generated jnr files from webgpu-to-java (https://github.com/MonstrousSoftware/java-to-webgpu)
to the libgdx backend (backends.webgpu.webgpu) (maybe the folder name could be better).
Needed to adapt the jnr generator to create the correct package name and import statements.

Resource folder added under gdx-backend-webgpu for the DLL files. (todo subdir per platform).
Shader source was added as a String to the HelloTriangle code to avoid too many loose files.

HelloTriangle test now works (calling GLFW and native WebGPU directly).

WebGPUTest uses WebGPUApplication and some native WebGPU calls to render a triangle.
The listener needs to create its own render pass (this will later be done by SpriteBatch or ModelBatch),
while WebGPUWindow.update() obtains the next render surface and presents the target view.
Update: the command encoder is created and finished in Window, and can be obtained via app.getCommandEncoder(),
render pass is created in Listener (because you may want multiple render passes).

LibGDX supports multiple windows per application.  This does not work yet for WebGPU (crash).

For audio, the webgpu backend simply refers to the lwjgl3 backend, so we don't duplicate non-graphics code.
This means we can remove the audio subfolder from gdx-backend-webgpu.



6/5/2024:
Crash of Application.newWindow() was because of the sharedContext parameter which seems related to GL context.  Crash fixed by passing a 0 instead.
To think which resources should be maintained at window level rather than application level, e.g. surface, device?, queue?
Moved surface, device, queue, targetView and commandEncoder to Window.  Application exposes these resource to user code by passing the resources from the current window.
WebGPU initialisation is mostly done at Window level now.

WebGPUTest now can create multiple windows. Use a mouse click in the window to create a child window.
Application exits when last window is closed.

Note: had to rename the .github/workflows folder (as a way to disable the workflows) to avoid push conflicts with automatic formatting workflows
and getting regular emails about missing permissions.

Next steps:
- include WebGPU abstraction classes
- SpriteBatch / Mesh

Created a wrapper folder which contain Java convenience classes of several WebGPU concepts (device, adapter, command encoder, buffer, etc.)
The webgpu code in Window was adapted to use these classes.
To get the raw pointer to use e.g. in a webgpu function call, use the getHandle() method.

Instead of replicating the internals of libgdx SpriteBatch (e.g. using a Mesh) we use a version that is functionally equivalent.

WGPUTexture still needs to be aligned to Texture.

RenderPassBuilder and PipelineSpecification need cleaning up or replacing.

VertexAttributes is reinvented. To be aligned. FIXED

Added depth texture to Window. Applcation exports textureview and textureformat (needed to build render pass).

07/05:
Many classes need access to the webGPU instance and the app instance (because this gives access to device, queue, etc.)
(app instance actually relies on current Window).  So many classes include the following type of code:

        public class WebGPUBindGroup implements Disposable {
            private final WebGPUApplication app;
            private final WebGPU_JNI webGPU;


            public WebGPUBindGroup(WebGPUBindGroupLayout layout) {
                app = (WebGPUApplication) Gdx.app;
                webGPU = app.getWebGPU();
                ...
            }
        }

This is the equivalent of libgdx code using Gdx.gl and Gdx.app but unfortunately more wordy (since we don't want to modify Gdx itself).

Perhaps we should put the WebGPU context in Graphics rather than Window, then we can use:
    WebGPUGraphics gfx = (WebGPUGraphics)Gdx.graphics;
    WebGPU_JNI webGPU = gfx.getWebGPU();
    gfx.getDevice()
    gfx.getQueue() etc.

Still just as wordy, but more logical.


Perhaps PipelineLayout should be integrated into PipelineSpec.  These are 2 objects required to create or find a pipeline.

libgdx VertexAttributes uses a String as alias to bind with shader code.  In webgpu we use an integer to bind.
WebGPU has a vertex format enum that gives type and number of components, e.g. Uint8x4 whereas libgdx uses type (e.g. GL_FLOAT) + numComponents

Got WebGPUSpriteBatch to work to display a texture.  SpriteBatch and Texture are internally very different from the libgdx equivalent.

Should WebGPUSpriteBatch extend SpriteBatch? This way we don't have to copy all the draw methods, setColor, etc.

Also if WebGPUTexture extends Texture we can supply WebGPUTexture as draw parameter (but it would also accept a regular Texture
which is an error).

In the Vulkan version by Stephan Lebed, a regular Texture is accepted but cast to VulkanTexture, which seems dangerous...
His VulkanTexture extends Texture.
Note that his VulkanSpriteBatch implements Batch (i.e. implements all methods).

        @Override
        public void draw(Texture texture, float[] spriteVertices, int offset, int count) {
            if (!drawing) throw new IllegalStateException("Batch.begin must be called before draw.");


            VulkanTexture vkTexture = (VulkanTexture) texture;


WebGPUTexture was brought more in line with Texture and now extends Texture.  Uses Pixmap and TextureData.
The Texture.data member had to be duplicated because it is package private and cannot be accessed by the subclass.
To check if managed textures work and if pixmaps are disposed properly.

Added a label parameter to some of the different Texture constructurs, e.g. the source file name to aid with debugging.

WebGPUSpriteBatch
-----------------
- The blend methods use values of type WGPUBlendFactor (e.g. WGPUBlendFactor.SrcAlpha) instead of int (e.g. GL_SRC_ALPHA). To differentiate
the methods are called xxxxFactor instead of xxxxFunc.  The original methods are also provide and perform a translation to/from GL constants to ensure
the WebGPUSpriteBatch is compatible with Batch.
- setShader() variant with WebGPUShaderProgram instead of ShaderProgram.
- getShader() always returns null.
- The blendOpColor and blendOpAlpha are not modified by spritebatch methods and is set to Add.
- begin() has an extra optional Color parameter to set the background colour (to use instead of glClear())
- whereas the libgdx SpriteBatch can handle more sprites than fit in the vertex buffer by flushing and restarting, this does not work
for WebGPU as the buffer cannot be reused after each draw call but needs to be maintained until the end of the frame.
If there are too many sprites an exception is thrown. In such a case, use a larger number in the sprite batch constructor.
(Another option would be to silently discard the last rectangles.)

TextureRegion
-------------
This works out of the box as long as you provide a WebGPUTexture as input. (You cannot create a Texture anyway without a GL context).

Sprite
------
Works out of the box as long as you provide a WebGPUTexture as input.

BitmapFont
-----------
Had to be copied to WebGPUBitmapFont because it calls new Texture which should be new WebGPUTexture. (line 134)
Glyph subclass is used from the original.
This also means BitmapFontCache and GlyphLayout need to be copied because of type changes from BitmapFont to WebGPUBitmapFont.
Unfortunately , that's a lot of duplicated lines for a few trivial changes. But it now works.

Managed to fix it without copying too many other classes, just by overriding all the constructors.


Stage
-----
Made WebGPUStage to extend Stage.
Calls Group.setStage which is package private, idem for Actor.setParent().
Made a few changes in core to make methods public, marked with // MM comment.

Alternative approach: call Stage but supply viewport and batch.

Viewport: troublemaker is line 49: 		HdpiUtils.glViewport(screenX, screenY, screenWidth, screenHeight);
Use WebGPUViewport which overrides apply().
The other viewport types need to derive from WebGPUViewport.

TextureAtlas: contains new Texture in the load method.  Tried to extend TextureAtlas and just replace load()
but many textures and regions are private.

Stage now works and different Scene2d UI elements.
The only difference from the regular Stage is in the constructors to make sure to use a WebGPUSpriteBatch and WebGPUViewport.
You can also use the regular Stage if you use the constructor that injects spritebatch and view port.

On resize the UI looks bad. Viewport is not yet implemented... Or perhaps it is due to filtering.

Images in Scene2d appear upside down.

Core changes (access modified):
Actor.java  	    355 public void setParent (@Null Group parent) {
Dialog.java         119 public void setStage (Stage stage)
Group.java          403 public void setStage (Stage stage)
SelectBox.java      591 public void setStage
Update 22/05: These changes are no longer needed and were reverted.



next steps:
- ScreenUtils
- view ports
- ShapeRenderer

Actor calls ScissorStack which makes GL calls.

Core changes:
ScrollPane.java line 541  //		if (clipBegin(actorArea.x, actorArea.y, actorArea.width, actorArea.height)) {			// MonstrousSoftware
Idem for Table.java


If you extract font from a WebGPUSkin, then you can use it as is:
			BitmapFont font = skin.get("default-font", BitmapFont.class);

ScreenUtils
-----------
Implemented the clear() methods, but only for color, not for depth.  It is quite expensive as it creates a SpriteBatch to do this
for each call.  (If you create a static SpriteBatch, it fails if you start the applicationListener multiple times, e.g. from the TestStarter.  Probably because in that case the SpriteBatch
is never disposed, and then reused in an incorrect context.)

Preferred way to clear the screen is to use SpriteBatch.begin(clearColor); which is a new functionality of SpriteBatch.



12/05/2025:
-updated intellij to 2025.1.1.1 (Community Edition).
- fresh clone from https://github.com/MonstrousSoftware/libgdx
- Error: Unable to read file for extraction: gdx64.dll   => ./gradlew fetchNatives
- Resource not found: dawn.dll => Created new folder (normal folder, not a module) 'res' under gdx-backend-webgpu (at same level as src). Added dawn.dll and webgpuUtils.dll.

Scene2dTest bugs:
- moving image is the incorrect texture ; FIXED
- debug lines are not visible (known limitation)
- checkbox image is upside down : FIXED
- some buttons in the vertical button row are not visible. This is because of the patch that is drawn (maybe because the scissoring is disabled?).

13/05/2025:
- Started work on 3d rendering:
    - WebGPUIndexData which implements interface IndexData,
    - WebGPUVertexData which implements interface VertexData,
    - WebGPUMesh which is derived from Mesh

    WebGPUMesh has a new bind method and render method which take a render pass (instead of a ShaderProgram).

    Note: Mesh.vertices is package private, but was made protected so we can access it from WebGPUMesh (core change). Note that there is a Mesh.getIndexData() but not
    an equivalent Mesh.getVertexData().  We want access to vertices to bind it to the render pass.

    WebGPUTestMesh is a test app for WebGPUMesh.

- Migrated to standard VertexAttribute/VertexAttributes
    - The new class WebGPUVertexLayout has a factory method to construct a vertex layout from VertexAttributes, mapping GL constants to WebGPU formats.



MeshPart can almost be used unchanged, except it provides render methods that take a ShaderProgram and we need to provide a RenderPass.

Tried a trick to derive ShaderProgram into a Pass class, but ShaderProgram has no no-args constructor and the existing constructor will compile shader coder or throw an exception.
Derived WebGPUMeshPart instead, overriding a few methods.

Folder structure in backend:
- gdx           code replicating classes from gdx.graphics and gdx.scene2d core
- lwjgl3        platform-specific code for desktop using LWJGL3 and GLFW
- utils         utility functions related to JNR-FFI mechanism
- webgpu        generated Java code to interface with Dawn via JNR-FFI
- wrappers      Java classes corresponding to some WebGPU concepts, e.g. adapter, pipeline, texture, etc.



15/05/2025:
- Separated out the backend into a platform specific part (gdx-backend-lwjgl3_webgpu) and a shared part (gdx-backend-webgpu). This
opens up the possibility to add different platform backends.

19/05/2025:
- Experimented with having WebGPUSpriteBatch make use of WebGPUMesh, like SpriteBatch does.  This would mean some reuse of code and an interesting use case for Mesh.
This worked but not very efficiently.  In particular there is no means to copy each batch to a particular offset in the GPU vertex buffer (For OpenGL this is not an issue because the vertex buffer can be reused after draw).
Mesh.setVertices always copies the data to the start of the vertex data.
Also, it ended up with multiple backing buffers (WebGPUVertexData has a backing buffer to support getVertices()).  So in the end, I went back to directly using VertexBuffer and IndexBuffer and using a
FloatBuffer to transfer vertex data per batch flush.


Worked out why textures were upside down in Scene2d. This is because it mostly draws textureRegions and SpriteBatch is supposed to switch v and v2 for textureRegions.
Fixed. To check all possible combinations of SpriteBatch.draw...

Fixed the issue with Scene2dTest that the moving image was the wrong texture.  This was due to some of teh SpriteBatch.draw calls now calling numSprites++.

Scene2dTest mostly works now except for debug lines and drawing the TiledDrawable patch.

21/05/2025:
- Added NinePatchTest.  Fixed default texture filtering to Nearest to match LibGDX behaviour. g2d/NinePatch can eb used unaltered as long as you feed it WebGPUTextures, or TextureRegions that refer to one.


22/05/2025:
- Found an issue with ShapeRenderer that produces no output in a 2D scene. Turns out that Matrix4.setToOrtho() needs to be adapted to range Z from 0 to 1 instead of from -1 to 1
We render 2d shapes with a Z of 0 and we use depth compare of "Less"


When we set an ortho view instead of
    mat.setToOrtho2D(0, 0, w, h);
    (which gets translated to mat.setToOrtho(0, w, 0, h, 0, 1) )

we need to do
	mat.setToOrtho(0, w, 0, h, 1, -1);

This also needs to be clear to users, and will be easy to overlook.
Likewise when using an Ortho Camera for a 2d scene: cam.near must be set to 1 and cam.far to -1.
There is no point in using cam.projection.setToOrtho(....) because cam.update() recalculates the projection matrix.

Side bar: how did we arrive to near = 1 and far = -1?
The setOrtho code in Matrix4 uses:
    zOrtho = -2/(f-n)
    tz = -(f+n)/(f-n)

We want a zOrtho of 1 and tz of 0 (from comparison with Webgpu matrix calculations).

So, solve:
    -2/(f-n) = 1            I
    -(f+n)/(f-n) = 0        II

From II it follows f = -n and f <> n
Substitute in I to get -2/-2n = 1 => 1/n = 1 => n = 1
=> f = -1



Also note in example programs there are multiple SR.begin/end within render(). It seems we see only the last one.
This is also an issue with ImmediateModeRenderer and SpriteBatch.  flush() or end() does not actually send data to the CPU and allow the buffers to be reused.
The buffers can only be reused once the command buffer is sent to the graphics queue, which happens outside of ApplicationListener.render().
begin() resets the buffers to the start. Perhaps they should somehow know which is the first begin() of the frame and otherwise just continue filling the same buffer.
Or submit the command buffer as part of spritebatch.end(), shaperenderer.end() etc. or even at flush().

- Got debug lines more or less working in Stage.  We can set stage.setDebugAll(true) to have debug lines for all elements, of use Actor.setDebug(true).
Not all options are supported (e.g. debugUnderMouse...)

- To fix: when resizing scene2d things, e.g. the test starter menu, the button font becomes almost unreadable.


24/05/2025:
- did scene2d debug() stop working? ShapeRenderer2DTest still works.
=> Had to set near/far values in Viewport and Stage





05/06/2025:
- Now able to load .OBJ files and render via ModelInstance.
Note that the default OBJ asset (ship.obj) is not a good example as it is malformed, e.g. also in Blender or Windows 3d viewer.
I've used my ducky model for testing (added temporarily to assets folder, to add to a webgpu test assets folder).
Note that OBJ files need to be loaded with flipV set to true ot the texture will appear upside down.
Also note with Blender exporting that file names in the .mtl file are hard coded absolute paths and need to be made relative.
From the libgdx code comments it appears .OBJ support is limited and incomplete, with preference given to the own G3D formats.

- Added loader for G3DJ

There is a loader for G3DJ format, but it seems for the G3DB format you can only load via the AssetManager?
No, the same loader supports both the g3dj and g3db format, you just need to provide a different reader:
		model = new WebGPUG3dModelLoader(new JsonReader()).loadModel(file);   // g3dj
		model = new WebGPUG3dModelLoader(new UBJsonReader()).loadModel(file);   // g3db

knight.g3db (contains animations) causes crash.

To also test loading via AssetManager.
You can disable default loaders of Asset Manager via its constructor and provide alternative loaders.

		assets = new AssetManager( new InternalFileHandleResolver(), false);
		assets.setLoader(Model.class, ".g3dj", new G3dModelLoader(new JsonReader(), assets.getFileHandleResolver()));
		assets.setLoader(Model.class, ".g3db", new G3dModelLoader(new UBJsonReader(), assets.getFileHandleResolver()));



To fix: WebGPUTextures are pretty much assumed to be RBGA8888 regardless of image file format. We should support, e.g RGB888.
For now texture format is forced to RGBA.

To fix: select box drop down appears at 0,0 instead of just below the select box.

To fix: loading OBJ files via AssetManager gives no chance to flip the V coordinate.
Now will default to flip.

There is a lot of code duplication of ModelLoader and its derived classes ObjLoader and G3DLoader

6/6/2025:
Refactored as extension gdx-webgpu instead of as backend.





